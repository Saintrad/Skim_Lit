# -*- coding: utf-8 -*-
"""NLP_practice.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CWSVx7w-FMVl40Nw89yqJfjEtMH2GdU9

# Introduction: Replicating the PubMed 200k RCT Paper

In this notebook, we aim to replicate the deep learning approach introduced in the 2017 paper "PubMed 200k RCT: A Dataset for Sequential Sentence Classification in Medical Abstracts." This paper presented a groundbreaking dataset of approximately 200,000 labeled abstracts from randomized controlled trials (RCTs), designed to enable Natural Language Processing (NLP) models to classify sentences based on their sequential role in medical abstracts.

**The Problem**

As the number of published RCTs continues to grow, unstructured abstracts can be challenging to read efficiently. This can slow researchers down as they navigate through the vast scientific literature.

**The Solution**

We aim to build an NLP model capable of classifying each sentence in an abstract into its role—such as Objective, Methods, Results, or Conclusions. This capability allows researchers to skim abstracts more effectively (hence the name SkimLit) and dive deeper only when necessary.

Example Task
Given an input abstract like the one below (where numerical symbols have been replaced with "@"):

To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain, mobility, and systemic low-grade inflammation...

The model should produce a structured output like this:

['OBJECTIVE\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain, mobility...',
 'METHODS\tA total of @ patients with primary knee OA were randomized...',
 'RESULTS\tThere was a clinically relevant reduction in the intervention group...',
 'CONCLUSIONS\tLow-dose oral prednisolone had both a short-term and a longer sustained effect...']

**What This Notebook Covers**

Data Preparation: Download and preprocess the PubMed 200k RCT dataset from GitHub.

Model Baseline: Implement a baseline model using TF-IDF and a simple classifier.

Deep Learning Models: Experiment with a variety of neural network architectures, incorporating:

* Token embeddings

* Character embeddings

* Pretrained embeddings

* Positional embeddings

Multimodal Approaches: Build a multimodal model that combines multiple input types for improved performance.

Evaluation: Assess our models' performance and compare them to results in the original paper.

Firstly, we will have to download the data and take a look at it's structure.
"""

#!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git
#!ls pubmed-rct

#!ls pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/

import os
data_dir = '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'
filename=[]
for file in os.listdir(data_dir):
  filename.append(data_dir + file)
filename

def get_lines(filename):
  with open(filename, 'r') as f:
    return f.readlines()

train_lines = get_lines(data_dir+'train.txt')
train_lines[:20]

len(train_lines)

train_lines[0]

"""# Preprocessing and preparing the data

Now we write a preprocessing function for our data that will create a dictionary for each line in our text data, with the target value, text, line number of that line and the total number of lines in that particular abstact as these features could help imporve the perfo
"""

def preprocess_text_with_line_numbers(filename):
  """Returns a list of dictionaries of abstract line data.

  Takes in filename, reads its contents and sorts through each line,
  extracting things like the target label, the text of the sentence,
  how many sentences are in the current abstract and what sentence number
  the target line is.

  Args:
      filename: a string of the target text file to read and extract line data
      from.

  Returns:
      A list of dictionaries each containing a line from an abstract,
      the lines label, the lines position in the abstract and the total number
      of lines in the abstract where the line is from. For example:

      [{"target": 'CONCLUSION',
        "text": The study couldn't have gone better, turns out people are kinder than you think",
        "line_number": 8,
        "total_lines": 8}]
  """
  input_lines = get_lines(filename) # get all lines from filename
  abstract_lines = "" # create an empty abstract
  abstract_samples = [] # create an empty list of abstracts

  # Loop through each line in target file
  for line in input_lines:
    if line.startswith("###"): # check to see if line is an ID line
      abstract_id = line
      abstract_lines = "" # reset abstract string
    elif line.isspace(): # check to see if line is a new line
      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines

      # Iterate through each line in abstract and count them at the same time
      for abstract_line_number, abstract_line in enumerate(abstract_line_split):
        line_data = {} # create empty dict to store data from line
        target_text_split = abstract_line.split("\t") # split target label from text
        line_data["target"] = target_text_split[0] # get target label
        line_data["text"] = target_text_split[1].lower() # get target text and lower it
        line_data["line_number"] = abstract_line_number # what number line does the line appear in the abstract?
        line_data["total_lines"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)
        abstract_samples.append(line_data) # add line data to abstract samples list

    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence
      abstract_lines += line

  return abstract_samples

train_samples = preprocess_text_with_line_numbers(data_dir + 'train.txt')
val_samples = preprocess_text_with_line_numbers(data_dir + 'dev.txt')
test_samples = preprocess_text_with_line_numbers(data_dir + 'test.txt')
train_samples[:10]

"""We create pandas dataframes for our training, validation and test datasets. Furthermore, we will take a look at the distribution of the number of total lines in each dataset."""

import pandas as pd
train_df = pd.DataFrame(train_samples)
val_df = pd.DataFrame(val_samples)
test_df = pd.DataFrame(test_samples)
train_df.head()

train_df.target.value_counts()

train_df.total_lines.plot.hist();

"""Since one of our main inputs is the string of sentences, we will turn these into a list."""

train_sentences = train_df['text'].tolist()
val_sentences = val_df['text'].tolist()
test_sentences = test_df['text'].tolist()

"""It is required for our target values to be in numerical form as well so these values are one hot encoded and label encoded, since TensorFlow's Categorical Crossentropy loss function works better with one hot encoded labels."""

from sklearn.preprocessing import OneHotEncoder
one_hot_encoder = OneHotEncoder(sparse_output=False)
train_labels_one_hot = one_hot_encoder.fit_transform(train_df['target'].to_numpy().reshape(-1,1))
val_labels_one_hot = one_hot_encoder.transform(val_df['target'].to_numpy().reshape(-1,1))
test_labels_one_hot = one_hot_encoder.transform(test_df['target'].to_numpy().reshape(-1,1))

test_labels_one_hot[:10]

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()

train_labels_encoded = label_encoder.fit_transform(train_df['target'].to_numpy())
val_labels_encoded = label_encoder.transform(val_df['target'].to_numpy())
test_labels_encoded = label_encoder.transform(test_df['target'].to_numpy())

train_labels_encoded[:10]

"""# Creating and Training the models

Our initial model will be a TF-IDF Multinomial Naive Bayes, following the recommendation from Scikit-Learn's machine learning map.

We'll implement this model using a Scikit-Learn Pipeline. The pipeline will first utilize the TfidfVectorizer class to transform abstract sentences into numerical representations based on the TF-IDF (Term Frequency-Inverse Document Frequency) algorithm. Then, the MultinomialNB algorithm will be applied to classify these sentences into their respective categories.
"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline

model_0 = Pipeline([
    ('tf-idf', TfidfVectorizer()),
    ('clf', MultinomialNB())
])

model_0.fit(X=train_sentences, y=train_labels_encoded)

model_0.score(val_sentences, val_labels_encoded)

base_line_preds = model_0.predict(val_sentences)

"""We also write a calculate results function to easily calculate the accuracy, percision, recall and the f1 score of our models to compare them."""

from sklearn.metrics import accuracy_score , precision_recall_fscore_support
def calculate_results(y_true, y_pred):
  # Calculate model accuracy
  model_accuracy = accuracy_score(y_true, y_pred) * 100
  # Calculate model precision, recall and f1 score using "weighted" average
  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average="weighted")
  model_results = {"accuracy": model_accuracy,
                  "precision": model_precision,
                  "recall": model_recall,
                  "f1": model_f1}
  return model_results

base_line_results = calculate_results(val_labels_encoded, base_line_preds)
base_line_results

"""
**word level vectorization and embedding**

Before diving into building deeper models, we need to set up vectorization and embedding layers. The vectorization layer will transform our text into numerical representations, while the embedding layer will capture the relationships and patterns among these numerical values.

Since we’ll be converting sentences into numbers, it’s important to determine the length of each sentence.
To ensure our model processes sentences effectively, they need to be of uniform length. This is crucial for creating batches with tensors of the same size.
For example, if one sentence contains eight words and another has 29 words, we’ll pad the shorter sentence with zeros so that both have the same length.

In order to find the best length of sequences, we will take a look at the average length and the distribution of the length of our senences."""

import numpy as np
import tensorflow as tf
from tensorflow.keras import layers

sent_lens = [len(sentence.split()) for sentence in train_sentences]
avg_sent_lens = np.mean(sent_lens)
avg_sent_lens

import matplotlib.pyplot as plt
plt.hist(sent_lens, bins=20);

output_seq_len = int(np.percentile(sent_lens, 95))
output_seq_len

max(sent_lens)

"""The length of 55 seems reasonable since 95% of the data does not surpass this length and the the max length of 296 seems unreasonable because an unseemingly small amount of the data comes even close to that number."""

text_vectorizer = layers.TextVectorization(max_tokens=68000,
                                           standardize='lower_and_strip_punctuation',
                                           split='whitespace',
                                           output_sequence_length=55
                                           )
text_vectorizer.adapt(train_sentences)

rct_20k_vocab = text_vectorizer.get_vocabulary()

token_embed = layers.Embedding(input_dim=len(rct_20k_vocab),
                             output_dim=128,
                             mask_zero=True,
                             name='token_embedding'
                             )

"""We must also batch and prefetch our datasets to improve training speed and efficiency."""

train_ds = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_encoded))
val_ds = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_encoded))
test_ds = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_encoded))

train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)
val_ds = val_ds.batch(32).prefetch(tf.data.AUTOTUNE)
test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)

"""**Model 1 Conv1D model**

With a numerical representation of our text and labels in place, it’s time to build a series of deep learning models to improve upon our baseline.

All of our deep models will follow a similar architecture:  
**Input (text) → Tokenize → Embedding → Layers → Output (label probabilities)**  

The primary component we’ll experiment with is the **Layers** section, as modern deep NLP models rely on embeddings to uncover meaningful patterns in text.

Our first model will be a 1-dimensional Convolutional Neural Network (1D CNN).

We'll adhere to the standard machine learning workflow:  
1. **Build the model**  
2. **Train the model**  
3. **Evaluate the model** (make predictions and compare them to the ground truth)  

"""

inputs = layers.Input(shape=(1,), dtype=tf.string)
text_vectors = text_vectorizer(inputs)
token_embeddings = token_embed(text_vectors)
x = layers.Conv1D(64, kernel_size=5, padding='same', activation='relu')(token_embeddings)
x = layers.GlobalMaxPool1D()(x)
outputs = layers.Dense(5, activation='softmax')(x)

model_1 = tf.keras.Model(inputs, outputs)

model_1.summary()

train_ds, val_ds

model_1.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,
                optimizer=tf.keras.optimizers.Adam(),
                metrics=['accuracy'])
hsitory_model_1 = model_1.fit(train_ds,
                              epochs=3,
                              validation_data=val_ds,
                              steps_per_epoch=int(0.1*len(train_ds)),
                              validation_steps=int(0.1*len(val_ds))
                              )

model_1.evaluate(val_ds)

model_1_preds_probs = model_1.predict(val_ds)
model_1_preds = tf.argmax(model_1_preds_probs,axis=1)
model_1_preds

calculate_results(val_labels_encoded, model_1_preds)

"""**Model 2 Feature extraction with pretrained token embeddings**


"""

import tensorflow_hub as hub
tf_hub_embedding_layer = hub.KerasLayer("https://tfhub.dev/google/universal-sentence-encoder/4",
                                        trainable=False,
                                        name="universal_sentence_encoder")

class PretrainedEmbeddingLayer(tf.keras.Layer):
    def call(self, x):
        return tf_hub_embedding_layer(x)

import random
# Test out the embedding on a random sentence
random_training_sentence = random.choice(train_sentences)
print(f"Random training sentence:\n{random_training_sentence}\n")
use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])
print(f"Sentence after embedding:\n{use_embedded_sentence[0][:30]} (truncated output)...\n")
print(f"Length of sentence embedding:\n{len(use_embedded_sentence[0])}")

# Define feature extractor model using TF Hub layer
inputs = layers.Input(shape=[], dtype=tf.string)
pretrained_embedding = PretrainedEmbeddingLayer()(inputs) # tokenize text and create embedding
x = layers.Dense(128, activation="relu")(pretrained_embedding) # add a fully connected layer on top of the embedding
# Note: you could add more layers here if you wanted to
outputs = layers.Dense(5, activation="softmax")(x) # create the output layer
model_2 = tf.keras.Model(inputs=inputs,
                        outputs=outputs)

# Compile the model
model_2.compile(loss="categorical_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

model_2.summary()

history_model_2 = model_2.fit(train_ds,
                              epochs=3,
                              validation_data=val_ds,
                              validation_steps=int(0.1*len(val_ds)),
                              steps_per_epoch=int(0.1*len(train_ds))
                              )

model_2.evaluate(val_ds)

model_2_pred_probs = model_2.predict(val_ds)
model_2_preds = tf.argmax(model_2_pred_probs, axis=1)
model_2_preds

calculate_results(val_labels_encoded,
                  model_2_preds)

"""**Model 3: Conv1D with character embeddings**

Now, instead of token embeddings we will use character embeddings. Firstly we create a function to split our sentences into the characters then calculate the maximum number of characters and the distrbution of the length of sentences in our datasets, much like our approach with token embeddings. Later on, we will use these numbers to finalize the character embeddings.
"""

def split_chars(text):
  return " ".join(list(text))

import string
alphabet = string.ascii_lowercase + string.punctuation + string.digits

train_chars = [split_chars(sentence) for sentence in train_sentences]
val_chars = [split_chars(sentence) for sentence in val_sentences]
test_chars = [split_chars(sentence) for sentence in test_sentences]

char_lens = [len(sentence) for sentence in train_sentences]
mean_char_len = np.mean(char_lens)
mean_char_len

plt.hist(char_lens, bins=7);

output_seq_len = int(np.percentile(char_lens, 95))
output_seq_len

NUM_CHAR_TOKENS = len(alphabet) + 2
char_vectorizer = layers.TextVectorization(max_tokens=NUM_CHAR_TOKENS,
                                    output_sequence_length=output_seq_len,
                                    name='char_vectorizer',
                                    )
char_vectorizer.adapt(train_chars)

random_char_vector = char_vectorizer([train_chars[0]])
random_char_vector

vocab_size = len(char_vectorizer.get_vocabulary())
char_embed = layers.Embedding(input_dim=vocab_size,
                              output_dim=25,
                              mask_zero=False,
                              name='char_embed')

char_train_ds = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_encoded)).batch(32).prefetch(tf.data.AUTOTUNE)
char_val_ds = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_encoded)).batch(32).prefetch(tf.data.AUTOTUNE)
char_test_ds = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_encoded)).batch(32).prefetch(tf.data.AUTOTUNE)
char_train_ds

"""Now that our datasets and embedding layers are ready, we will create a conv1D model with character embeddings and train it on our data."""

inputs = layers.Input(shape=(1,), dtype=tf.string)
char_vectors = char_vectorizer(inputs)
char_embeds = char_embed(char_vectors)
x = layers.Conv1D(64, kernel_size=5, padding='same', activation='relu')(char_embeds)
x = layers.GlobalMaxPooling1D()(x)
outputs = layers.Dense(5, activation='softmax')(x)
model_3 = tf.keras.Model(inputs, outputs)

model_3.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,
                optimizer=tf.keras.optimizers.Adam(),
                metrics=['accuracy'])
model_3.summary()

history_model_3 = model_3.fit(char_train_ds,
                              epochs=3,
                              validation_data=char_val_ds,
                              steps_per_epoch= int(0.1*len(char_train_ds)),
                              validation_steps=int(0.1*len(char_val_ds)))

model_3.evaluate(char_val_ds)

model_3_pred_probs = model_3.predict(char_val_ds)
model_3_preds = tf.argmax(model_3_pred_probs, axis=1)

calculate_results(val_labels_encoded, model_3_preds)

"""**Model 4: Combining pretrained token embeddings + character embeddings (hybrid embedding layer)**

For our next approach, we will use both character level and word level embeddings. we will concatenate the outputs of a token embedding layer and a character embedding layer and feed that into a Dense layer.
"""

token_inputs = layers.Input(shape=[], dtype=tf.string)
token_embeddings = tf_hub_embedding_layer(token_inputs)
token_outputs = layers.Dense(128, activation='relu')(token_embeddings)
token_model = tf.keras.Model(inputs=token_inputs, outputs=token_outputs)

char_inputs = layers.Input(shape=(1,), dtype=tf.string)
char_vectors = char_vectorizer(char_inputs)
char_embeddings = char_embed(char_vectors)
char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)
char_model = tf.keras.Model(inputs=char_inputs, outputs=char_bi_lstm)

token_char_concat = layers.Concatenate(name='token-char_hybrid')([token_model.output,
                                                                  char_model.output])

combined_dropout = layers.Dropout(0.5)(token_char_concat)
combined_dense = layers.Dense(128, activation='relu')(combined_dropout)
final_dropout = layers.Dropout(0.5)(combined_dense)
output_layer = layers.Dense(5, activation='softmax')(final_dropout)

model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],
                         outputs=output_layer)
model_4.summary()

from keras.utils import plot_model
plot_model(model_4, show_shapes=True)

model_4.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,
                optimizer=tf.keras.optimizers.Adam(),
                metrics=['accuracy'])

train_token_char_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars))
train_token_char_labels = tf.data.Dataset.from_tensor_slices(train_labels_encoded)
train_char_token_ds = tf.data.Dataset.zip((train_token_char_data, train_token_char_labels))

train_char_token_ds = train_char_token_ds.batch(32).prefetch(tf.data.AUTOTUNE)

val_token_char_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))
val_token_char_labels = tf.data.Dataset.from_tensor_slices(val_labels_encoded)
val_char_token_ds = tf.data.Dataset.zip((val_token_char_data, val_token_char_labels))

val_char_token_ds = val_char_token_ds.batch(32).prefetch(tf.data.AUTOTUNE)

history_model_4 = model_4.fit(train_char_token_ds,
                              epochs=3,
                              validation_data=val_char_token_ds,
                              validation_steps=int(0.1*len(val_char_token_ds)),
                              steps_per_epoch=int(0.1*len(train_char_token_ds)))

model_4.evaluate(val_char_token_ds)

model_4_pred_probs = model_4.predict(val_char_token_ds)
model_4_preds = tf.argmax(model_4_pred_probs, axis=1)

calculate_results(val_labels_encoded, model_4_preds)

train_line_numbers_one_hot = tf.one_hot(train_df['line_number'].to_numpy(), depth=15)
val_line_numbers_one_hot = tf.one_hot(val_df['line_number'].to_numpy(), depth=15)
test_line_numbers_one_hot = tf.one_hot(test_df['line_number'].to_numpy(), depth=15)

train_df['total_lines'].value_counts()

train_df.total_lines.plot.hist();

train_total_lines_one_hot = tf.one_hot(train_df['total_lines'].to_numpy(), depth=20)
val_total_lines_one_hot = tf.one_hot(val_df['total_lines'].to_numpy(), depth=20)
test_total_lines_one_hot = tf.one_hot(test_df['total_lines'].to_numpy(), depth=20)

token_inputs = layers.Input(shape=[], dtype=tf.string)
token_embeddings = tf_hub_embedding_layer(token_inputs)
token_outputs = layers.Dense(128, activation='relu')(token_embeddings)
token_model = tf.keras.Model(inputs=token_inputs, outputs=token_outputs)

char_inputs = layers.Input(shape=(1,), dtype=tf.string)
char_vectors = char_vectorizer(char_inputs)
char_embeds = char_embed(char_vectors)
char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeds)
char_model = tf.keras.Model(inputs=char_inputs, outputs=char_bi_lstm)

line_num_inputs = layers.Input(shape=(15,), dtype=tf.float32)
line_num_outputs = layers.Dense(32, activation='relu')(line_num_inputs)
line_num_model = tf.keras.Model(inputs=line_num_inputs, outputs=line_num_outputs)

total_line_num_inputs = layers.Input(shape=(20,), dtype=tf.float32)
total_line_num_outputs = layers.Dense(32, activation='relu')(total_line_num_inputs)
total_line_num_model = tf.keras.Model(inputs=total_line_num_inputs, outputs=total_line_num_outputs)

combined_embeddings = layers.Concatenate()([token_model.output, char_model.output])
x = layers.Dense(256, activation='relu')(combined_embeddings)
x = layers.Dropout(0.5)(x)

tribrid_embeddings = layers.Concatenate()([line_num_model.output,
                                           total_line_num_model.output,
                                           x])
output_layer = layers.Dense(5, activation='softmax')(tribrid_embeddings)

model_5 = tf.keras.Model(inputs=[line_num_model.input,
                                 total_line_num_model.input,
                                 token_model.input,
                                 char_model.input],
                          outputs=output_layer)

plot_model(model_5, show_shapes=True)

model_5.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,
                optimizer=tf.keras.optimizers.Adam(),
                metrics=['accuracy'])

tribrid_train_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot,
                                                       train_total_lines_one_hot,
                                                       train_sentences,
                                                       train_chars))
tribrid_train_labels = tf.data.Dataset.from_tensor_slices(train_labels_encoded)
tribrid_train_ds = tf.data.Dataset.zip(tribrid_train_data, tribrid_train_labels)
tribrid_train_ds = tribrid_train_ds.batch(32).prefetch(tf.data.AUTOTUNE)


tribrid_val_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,
                                                      val_total_lines_one_hot,
                                                       val_sentences,
                                                       val_chars))
tribrid_val_labels = tf.data.Dataset.from_tensor_slices(val_labels_encoded)
tribrid_val_ds = tf.data.Dataset.zip(tribrid_val_data, tribrid_val_labels)
tribrid_val_ds = tribrid_val_ds.batch(32).prefetch(tf.data.AUTOTUNE)

tribrid_train_ds

history_model_5 = model_5.fit(tribrid_train_ds,
                              epochs=3,
                              validation_data=tribrid_val_ds,
                              steps_per_epoch=int(0.1*len(tribrid_train_data)/32),
                              validation_steps=int(0.1*len(tribrid_val_data)/32))

model_5.evaluate(tribrid_val_ds)

model_5_pred_probs = model_5.predict(tribrid_val_ds)
model_5_preds = tf.argmax(model_5_pred_probs, axis=1)

calculate_results(val_labels_encoded, model_5_preds)

model_0_results = calculate_results(val_labels_encoded, base_line_preds)
model_1_results = calculate_results(val_labels_encoded, model_1_preds)
model_2_results = calculate_results(val_labels_encoded, model_2_preds)
model_3_results = calculate_results(val_labels_encoded, model_3_preds)
model_4_results = calculate_results(val_labels_encoded, model_4_preds)
model_5_results = calculate_results(val_labels_encoded, model_5_preds)

all_model_results = pd.DataFrame({
    'model_0_baseline': model_0_results,
    'model_1_custom_token_embedding': model_1_results,
    'model_2_pretrained_token_embedding': model_2_results,
    'model_3_custom_char_embedding': model_3_results,
    'model_4_combined_token_char_embeding': model_4_results,
    'model_5_combined_token_char_pos_embedding': model_5_results
})

all_model_results = all_model_results.transpose()
all_model_results

all_model_results['accuracy'] = all_model_results['accuracy']/100

all_model_results.plot(kind='bar', figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));

all_model_results.sort_values('f1', ascending=True)['f1'].plot(kind='bar', figsize=(10,7))

test_data = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot,
                                              test_total_lines_one_hot,
                                              test_sentences,
                                              test_chars))
test_labels = tf.data.Dataset.from_tensor_slices(test_labels_encoded)
test_ds = tf.data.Dataset.zip(test_data, test_labels)
test_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)

model_5_test_pred_probs = model_5.predict(test_ds)
model_5_test_preds = tf.argmax(model_5_test_pred_probs, axis=1)

model_5_test_results = calculate_results(test_labels_encoded, model_5_test_preds)
model_5_test_results